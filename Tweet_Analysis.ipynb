{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gS3YnNNI8oFk",
        "cCZrclc2COWW",
        "7HpxZKYdD6V-",
        "EN-houoSD-hP",
        "ZJENUdF3F7Rn",
        "AcRdDiEtGQj4",
        "wcvt_7emuKlR",
        "g_roVSSRt-7h",
        "iBs9V61EGh0J",
        "UpwErZOgX_nC",
        "U0W3DWgWJCWs",
        "eT1jhk8xdod5"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtAgo5zYCClj"
      },
      "source": [
        "#  Natural Language Processing with TensorFlow\n",
        "\n",
        "\n",
        "The main goal of [natural language processing (NLP)](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32) is to derive information from natural language.\n",
        "\n",
        "\n",
        "```\n",
        "Text -> turn into numbers -> build a model -> train the model to find patterns -> use patterns (make predictions)\n",
        "```\n",
        "\n",
        "\n",
        "## What we're going to cover\n",
        "\n",
        "Let's get specific hey?\n",
        "\n",
        "* Downloading a text dataset\n",
        "* Visualizing text data\n",
        "* Converting text into numbers using tokenization\n",
        "* Turning our tokenized text into an embedding\n",
        "* Modelling a text dataset\n",
        "  * Building several deep learning text models\n",
        "    * Dense, LSTM, GRU, Conv1D, Transfer learning\n",
        "* Comparing the performance of each our models\n",
        "* Combining our models into an ensemble\n",
        "* Saving and loading a trained model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS3YnNNI8oFk"
      },
      "source": [
        "##  Helper functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Unzips filename into the current working directory.\n",
        "  Args:\n",
        "    filename (str): a filepath to a target zip folder to be unzipped.\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()"
      ],
      "metadata": {
        "id": "FvZ_o5CbkDfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Creates a TensorBoard callback instand to store log files.\n",
        "  Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "  Args:\n",
        "    dir_name: target directory to store TensorBoard log files\n",
        "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n"
      ],
      "metadata": {
        "id": "8qZp6HybkEnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  Args:\n",
        "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();"
      ],
      "metadata": {
        "id": "oYPglh0dkPYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_historys(original_history, new_history, initial_epochs=5):\n",
        "    \"\"\"\n",
        "    Compares two TensorFlow model History objects.\n",
        "    \n",
        "    Args:\n",
        "      original_history: History object from original model (before new_history)\n",
        "      new_history: History object from continued model training (after original_history)\n",
        "      initial_epochs: Number of epochs in original_history (new_history plot starts from here) \n",
        "    \"\"\"\n",
        "    \n",
        "    # Get original history measurements\n",
        "    acc = original_history.history[\"accuracy\"]\n",
        "    loss = original_history.history[\"loss\"]\n",
        "\n",
        "    val_acc = original_history.history[\"val_accuracy\"]\n",
        "    val_loss = original_history.history[\"val_loss\"]\n",
        "\n",
        "    # Combine original history with new history\n",
        "    total_acc = acc + new_history.history[\"accuracy\"]\n",
        "    total_loss = loss + new_history.history[\"loss\"]\n",
        "\n",
        "    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
        "    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
        "\n",
        "    # Make plots\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(total_acc, label='Training Accuracy')\n",
        "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(total_loss, label='Training Loss')\n",
        "    plt.plot(total_val_loss, label='Validation Loss')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xK22coIlka9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCZrclc2COWW"
      },
      "source": [
        "## Download a text dataset\n",
        " We'll be using the [Real or Not?](https://www.kaggle.com/c/nlp-getting-started/data) datset from Kaggle which contains text-based Tweets about natural disasters. \n",
        "\n",
        "The Real Tweets are actually about diasters, for example:\n",
        "\n",
        "```\n",
        "Jetstar and Virgin forced to cancel Bali flights again because of ash from Mount Raung volcano\n",
        "```\n",
        "\n",
        "The Not Real Tweets are Tweets not about diasters (they can be on anything), for example:\n",
        "\n",
        "```\n",
        "'Education is the most powerful weapon which you can use to change the world.' Nelson #Mandela #quote\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0FEcci5IH8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c290f38f-0058-4120-b05e-7698988ea18c"
      },
      "source": [
        "# Download data (same as from Kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-05 17:30:41--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.194.128, 173.194.195.128, 173.194.196.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-09-05 17:30:41 (29.4 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBIR6tTI9QcR"
      },
      "source": [
        "Unzipping `nlp_getting_started.zip` gives the following 2`.csv` files:\n",
        "\n",
        "* `train.csv` - training samples of real and not real diaster Tweets.\n",
        "* `test.csv` - testing samples of real and not real diaster Tweets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HpxZKYdD6V-"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRvkeYEJIKsw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "934c66dd-c200-420f-a623-76b71ea6a443"
      },
      "source": [
        "# Turn .csv files into pandas DataFrame's\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8eaa34c9-da5b-43ac-9353-f61dff99280d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8eaa34c9-da5b-43ac-9353-f61dff99280d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8eaa34c9-da5b-43ac-9353-f61dff99280d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8eaa34c9-da5b-43ac-9353-f61dff99280d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xGqlnQaLmaT"
      },
      "source": [
        "The training data we downloaded is probably shuffled already. But just to be sure, let's shuffle it again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACCE7h6OMVjR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0318e333-eaa6-4868-cedf-c6060a2e1cf1"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-724b3a23-7f5c-4560-81da-71965cfc0bf5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-724b3a23-7f5c-4560-81da-71965cfc0bf5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-724b3a23-7f5c-4560-81da-71965cfc0bf5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-724b3a23-7f5c-4560-81da-71965cfc0bf5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw4mKW1yL0kI"
      },
      "source": [
        "Notice how the training data has a `\"target\"` column.\n",
        "\n",
        "\n",
        "\n",
        "The test dataset doesn't have a `\"target\"` column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDh5t7thI5BM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ef72c446-ed8d-4bdc-f5f2-b5ff46cf1d17"
      },
      "source": [
        "# The test data doesn't have a target (that's what we'd try to predict)\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a7d518d-465f-4748-81d9-6ef668f0cd4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a7d518d-465f-4748-81d9-6ef668f0cd4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a7d518d-465f-4748-81d9-6ef668f0cd4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a7d518d-465f-4748-81d9-6ef668f0cd4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4JhBRn5Mn-V"
      },
      "source": [
        "Let's check how many examples of each target we have."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4P5DnLhIciD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde5a202-83a1-440b-aeea-ce1f2dbd560c"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjEDQ297Ihy4"
      },
      "source": [
        "Since we have two target values, we're dealing with a **binary classification** problem.\n",
        "\n",
        "It's fairly balanced too, about 60% negative class (`target = 0`) and 40% positive class (`target = 1`).\n",
        "\n",
        "Where, \n",
        "\n",
        "* `1` = a real disaster Tweet\n",
        "* `0` = not a real disaster Tweet\n",
        "\n",
        "And what about the total number of samples we have?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQxg7EKKIy5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d78a51-de08-4cea-d50b-23c9b3b185dd"
      },
      "source": [
        "# How many samples total?\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 7613\n",
            "Total test samples: 3263\n",
            "Total samples: 10876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH3EXknTI3bQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57782902-d00a-46dd-ef3b-a283851f981c"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Injuries may be forgiven but not forgotten.\n",
            "\n",
            "Aesop\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Only you can prevent forest fires. ???? http://t.co/rGYUaKc0dR\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "#NowPlaying at #orchardalley in #LES of #nyc 'bioterror- manufactured fear and state repression' @abcnorio #gardens http://t.co/Ba2rRXUgsG\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Kakeru Teduka: Bfore 70years of today in Hiroshima it's exploded the one atomic bomd. It is so sad day.http://t.co/8Vzl1ns2iO\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@CranBoonitz So going to make any bomb threats? @HereticOfEthics\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FhRRewGPNS_"
      },
      "source": [
        "### Split data into training and validation sets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OJf31TQ-X8s"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
        "                                                                            random_state=42) # random state for reproducibility"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWGOTjanBaTQ",
        "outputId": "7d97b1cc-f9da-43ca-f13e-3683ae4be636"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqhvQK9wBTbw",
        "outputId": "1bce4ec2-2a97-4ff3-8588-cab5c6466374"
      },
      "source": [
        "# View the first 10 training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN-houoSD-hP"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "\n",
        "Our labels are in numerical form (`0` and `1`) but our Tweets are in string form.\n",
        "\n",
        "\n",
        "In NLP, there are two main concepts for turning text into numbers:\n",
        "* **Tokenization** - A straight mapping from word or character or sub-word to a numerical value. \n",
        "* **Embeddings** - An embedding is a representation of natural language which can be learned. Representation comes in the form of a **feature vector**. For example, the word \"dance\" could be represented by the 5-dimensional vector `[-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]`. It's important to note here, the size of the feature vector is tuneable. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UnRcM1PELHn"
      },
      "source": [
        "### Text vectorization (tokenization)\n",
        "\n",
        "\n",
        "\n",
        "We'll practice tokenzation (mapping our words to numbers) first.\n",
        "\n",
        "\n",
        "The `TextVectorization` layer takes the following parameters:\n",
        "* `max_tokens` - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens. \n",
        "* `standardize` - Method for standardizing text. Default is `\"lower_and_strip_punctuation\"` which lowers text and removes all punctuation marks.\n",
        "* `split` - How to split text, default is `\"whitespace\"` which splits on spaces.\n",
        "* `ngrams` - How many words to contain per token split, for example, `ngrams=2` splits tokens into continuous sequences of 2.\n",
        "* `output_mode` -  How to output tokens, can be `\"int\"` (integer mapping), `\"binary\"` (one-hot encoding), `\"count\"` or `\"tf-idf\"`.\n",
        "* `output_sequence_length` - Length of tokenized sequence to output. For example, if `output_sequence_length=150`, all tokenized sequences will be 150 tokens long.\n",
        "* `pad_to_max_tokens` - Defaults to `False`, if `True`, the output feature axis will be padded to `max_tokens` even if the number of unique tokens in the vocabulary is less than `max_tokens`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ3ZCINnR56H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77736609-64c8-4dcf-9007-52fa013bb004"
      },
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFGTRcw8Hv7R"
      },
      "source": [
        "Now let's create  `TextVectorization` ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYPcGwdbafmW"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0083KHXPO4m2"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syh0VB9wIHUq"
      },
      "source": [
        "Training data mapped! Let's try our `text_vectorizer` on a custom sentence ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uizmdJKvO2OW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46fb9fb-89f2-4f90-c8ef-c0bc17ee4a6c"
      },
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0RmAeplIW57"
      },
      "source": [
        " it seems we've got a way to turn our text into numbers . Notice the 0's at the end of the returned tensor, this is because we set `output_sequence_length=15`, meaning no matter the size of the sequence we pass to `text_vectorizer`, it always returns a sequence with a length of 15.\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nwNdgAZIhna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b51d2101-20e4-4aba-e1aa-7efe4466b92a"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\") \n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHyCdO0uEOkH"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "We've got a way to map our text to numbers. How about we go a step further and turn those numbers into an embedding?\n",
        "\n",
        "\n",
        "We can see what an embedding of a word looks like by using the [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer. \n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "* `input_dim` - The size of the vocabulary (e.g. `len(text_vectorizer.get_vocabulary()`).\n",
        "* `output_dim` - The size of the output embedding vector, for example, a value of `100` outputs a  feature vector of size 100 for each word.\n",
        "* `embeddings_initializer` - How to initialize the embeddings matrix, default is `\"uniform\"` which randomly initalizes embedding matrix with uniform distribution. \n",
        "* `input_length` - Length of sequences being passed to embedding layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsB4StymSk_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05dc2a4d-556a-4cc2-ba4b-3fa1bc1b22a0"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=max_length, # how long is each input\n",
        "                             name=\"embedding_1\") \n",
        "\n",
        "embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f0ef3db3c90>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfML_IzlSUho"
      },
      "source": [
        "\n",
        "\n",
        "How about we try it out on a sample sentence?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Re6Eew6SZnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7e2436-fea8-4d01-c53b-fdc14ee6949f"
      },
      "source": [
        "print(f\"Original text:\\n{sample_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer(sample_sentence))\n",
        "sample_embed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "There's a flood in my street!      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15, 128), dtype=float32, numpy=\n",
              "array([[ 0.00193231, -0.02467285,  0.01718021, ...,  0.03535685,\n",
              "        -0.0492254 , -0.00110654],\n",
              "       [-0.04284013, -0.01489798, -0.0159496 , ..., -0.01166106,\n",
              "         0.03061062,  0.01972148],\n",
              "       [ 0.04801924, -0.03876035,  0.03859853, ..., -0.00849985,\n",
              "        -0.02576587,  0.04858171],\n",
              "       ...,\n",
              "       [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "         0.00912381, -0.00024097],\n",
              "       [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "         0.00912381, -0.00024097],\n",
              "       [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "         0.00912381, -0.00024097]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Sn8o9pTBE5"
      },
      "source": [
        "Each token in the sentence gets turned into a length 128 feature vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJENUdF3F7Rn"
      },
      "source": [
        "## Modelling a text dataset\n",
        "\n",
        "\n",
        "*Once you've got your inputs and outputs prepared, it's a matter of figuring out which machine learning model to build in between them to bridge the gap.*\n",
        "\n",
        "Now that we've got a way to turn our text data into numbers, we can start to build machine learning models to model it.\n",
        "\n",
        "\n",
        " we'll be building the following:\n",
        "\n",
        "* **Model 1**: Feed-forward neural network (dense model)\n",
        "* **Model 2**: LSTM model\n",
        "* **Model 3**: GRU model\n",
        "* **Model 4**: Bidirectional-LSTM model\n",
        "* **Model 5**: 1D Convolutional Neural Network\n",
        "* **Model 6**: TensorFlow Hub Pretrained Feature Extractor\n",
        "* **Model 7**: Same as model 6 with 10% of training data\n",
        "\n",
        "\n",
        "\n",
        "Each experiment will go through the following steps:\n",
        "* Construct the model\n",
        "* Train the model\n",
        "* Make predictions with the model\n",
        "* Track prediction evaluation metrics for later comparison\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K354svk_bmdf"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        " let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLmNlDjIxGgJ"
      },
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noRJNm7dGNyh"
      },
      "source": [
        "### Model 1: A simple dense model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVMPUd3HTit5"
      },
      "source": [
        "# Create tensorboard callback (need to create a new one for each model)\n",
        "\n",
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pib8hHtu7vt1"
      },
      "source": [
        "Now we've got a TensorBoard callback function ready to go, let's build our first deep model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_rVtJA7yVBI"
      },
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized numbers\n",
        "x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding \n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYzsu36Y8JUe"
      },
      "source": [
        " Our model takes a 1-dimensional string as input (in our case, a Tweet), it then tokenizes the string using `text_vectorizer` and creates an embedding using `embedding`.\n",
        "\n",
        "We then (optionally) pool the outputs of the embedding layer to reduce the dimensionality of the tensor we pass to the output layer.\n",
        "\n",
        "\n",
        "\n",
        "Finally, we pass the output of the pooling layer to a dense layer with sigmoid activation (we use sigmoid since our problem is binary classification).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubq0ctLD8CQq"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crgltz1O9uku"
      },
      "source": [
        "Model compiled. Let's get a summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkJa-t8aTw1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a08b0cc-6b7e-4b3a-db9a-a8282f923fad"
      },
      "source": [
        "# Get a summary of the model\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH0JLyR09yYt"
      },
      "source": [
        "\n",
        " our model is compiled, let's fit it to our training data for 5 epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YRYpJIfTvHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e270392-dc70-4c44-bbbc-a98892708cdb"
      },
      "source": [
        "# Fit the model\n",
        "import datetime\n",
        "\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR, \n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20220905-173450\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 21ms/step - loss: 0.6094 - accuracy: 0.6916 - val_loss: 0.5357 - val_accuracy: 0.7572\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4691 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.3463 - accuracy: 0.8605 - val_loss: 0.4590 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.2848 - accuracy: 0.8923 - val_loss: 0.4641 - val_accuracy: 0.7927\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.2380 - accuracy: 0.9118 - val_loss: 0.4767 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZR5_j9C_LW-"
      },
      "source": [
        "\n",
        "Let's check our model's performance on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSTS87YGzuBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4a9d27-ec0d-4f4e-8b95-ab13ae7602b9"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4766846001148224, 0.787401556968689]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9dg2aba_VxK"
      },
      "source": [
        "And since we tracked our model's training logs with TensorBoard, how about we visualize them?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkinGcjQ_yI9"
      },
      "source": [
        "The TensorBoard.dev experiment for our first deep model :\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-tensorboard-dense-model-training-curves.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X7kbEmAzzxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf2936cd-519f-45cb-cc9d-f1bc599bf7fa"
      },
      "source": [
        "# Make predictions (these come back in the form of probabilities)\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40488204],\n",
              "       [0.7443311 ],\n",
              "       [0.997895  ],\n",
              "       [0.10889998],\n",
              "       [0.11143529],\n",
              "       [0.93556094],\n",
              "       [0.9134594 ],\n",
              "       [0.99253446],\n",
              "       [0.9715681 ],\n",
              "       [0.26570344]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWU5e1NLAKJ9"
      },
      "source": [
        "Since our final layer uses a sigmoid activation function, we get our predictions back in the form of probabilities.\n",
        "\n",
        "To convert them to prediction classes, we'll use `tf.round()`, meaning prediction probabilities below 0.5 will be rounded to 0 and those above 0.5 will be rounded to 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf-R_1vsz47P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117007a7-4b0d-446d-fc4a-1f08408624e0"
      },
      "source": [
        "# Turn prediction probabilities into single-dimension tensor of floats\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
        "model_1_preds[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc3ryY0yCHcI"
      },
      "source": [
        "Now we've got our model's predictions in the form of classes, we can use our `calculate_results()` function to compare them to the ground truth validation labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDEEhYTF0X1y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48e0dd9-368a-4c59-a596-12a47e0e4ec8"
      },
      "source": [
        "# Calculate model_1 metrics\n",
        "model_1_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.74015748031496,\n",
              " 'precision': 0.7914920592553047,\n",
              " 'recall': 0.7874015748031497,\n",
              " 'f1': 0.7846966492209201}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcRdDiEtGQj4"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "\n",
        "\n",
        "The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (`X`) and compute an output (`y`) based on all previous inputs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDERKwP_XWro"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "\n",
        "\n",
        "Our model is going to take on a very similar structure to `model_1`:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```\n",
        "\n",
        "The main difference will be that we're going to add an LSTM layer between our embedding and output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi3vjpFU46hi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c17be3-0931-4eef-d69e-e410068d8300"
      },
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "\n",
        "# Create LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWdt3bFRwG6w"
      },
      "source": [
        "# Compile model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2e_t8RFxgXG"
      },
      "source": [
        "And before we fit our model to the data, let's get a summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAjdfDfLwK_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cdfd1dc-5f64-4597-de3f-82c5739694a9"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgZ7ojDvwKcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9b6175-d3af-4adf-9cb1-d6e7000cd8b0"
      },
      "source": [
        "# Fit model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"LSTM\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20220905-173540\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 32ms/step - loss: 0.5100 - accuracy: 0.7416 - val_loss: 0.4566 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 6s 28ms/step - loss: 0.3176 - accuracy: 0.8717 - val_loss: 0.5138 - val_accuracy: 0.7756\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 6s 28ms/step - loss: 0.2201 - accuracy: 0.9152 - val_loss: 0.5858 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 28ms/step - loss: 0.1556 - accuracy: 0.9428 - val_loss: 0.6041 - val_accuracy: 0.7743\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.1076 - accuracy: 0.9594 - val_loss: 0.8746 - val_accuracy: 0.7507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c_lVbKLemrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fcf1332-fb98-4f2a-85b7-f727ffbea326"
      },
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[0.00712615],\n",
              "        [0.7873689 ],\n",
              "        [0.9996376 ],\n",
              "        [0.05679163],\n",
              "        [0.00258216],\n",
              "        [0.99962384],\n",
              "        [0.9217019 ],\n",
              "        [0.9997994 ],\n",
              "        [0.99949545],\n",
              "        [0.66457486]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ6ope-ddpOo"
      },
      "source": [
        "We can turn these prediction probabilities into prediction classes by rounding to the nearest integer (by default, prediction probabilities under 0.5 will go to 0 and those over 0.5 will go to 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFnIhtyE7hlb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8abadc5-6376-4026-ff19-e4893ff5b127"
      },
      "source": [
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTBy4poXd_7p"
      },
      "source": [
        "now let's use our `caculate_results()` function to evaluate our LSTM model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iHXv04y76vj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e462ce-4079-46f0-b373-a8bb26fbf119"
      },
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.06561679790026,\n",
              " 'precision': 0.7510077975908164,\n",
              " 'recall': 0.7506561679790026,\n",
              " 'f1': 0.7489268622514025}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0pAtADt8ju7"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters.\n",
        "\n",
        "\n",
        "\n",
        "The architecture of the GRU-powered model will follow the same structure we've been using:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoSCGq3H47Yo"
      },
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "\n",
        "# Build an RNN using the GRU cell\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "x = layers.GRU(64)(x) \n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBL1mb31hHDS"
      },
      "source": [
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvnksvkmha2A"
      },
      "source": [
        "What does a summary of our model look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVnB5yQeiAWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0973e534-c1d7-4ffd-9582-0b1367be4740"
      },
      "source": [
        "# Get a summary of the GRU model\n",
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvamg5JOh_jC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a926a9d8-2885-42b9-a536-3b05b22a93cd"
      },
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20220905-173625\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 34ms/step - loss: 0.5242 - accuracy: 0.7314 - val_loss: 0.4553 - val_accuracy: 0.7769\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 7s 30ms/step - loss: 0.3195 - accuracy: 0.8694 - val_loss: 0.4937 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 7s 34ms/step - loss: 0.2197 - accuracy: 0.9181 - val_loss: 0.5607 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 30ms/step - loss: 0.1599 - accuracy: 0.9441 - val_loss: 0.6220 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.1221 - accuracy: 0.9584 - val_loss: 0.6205 - val_accuracy: 0.7677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM4mQj1Sh7Gn"
      },
      "source": [
        "\n",
        "\n",
        "Time to make some predictions on the validation samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5TUVHCl9pe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63694329-c9f6-4154-f413-1030fc86aa91"
      },
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1), array([[0.333252  ],\n",
              "        [0.877412  ],\n",
              "        [0.9980252 ],\n",
              "        [0.11561716],\n",
              "        [0.01235956],\n",
              "        [0.9925637 ],\n",
              "        [0.6214276 ],\n",
              "        [0.9981333 ],\n",
              "        [0.9982377 ],\n",
              "        [0.50181204]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hasS7dzRiYQh"
      },
      "source": [
        "Again we get an array of prediction probabilities back which we can convert to prediction classes by rounding them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haILbddg98CY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093bd190-b389-468b-bc5c-e590dd237196"
      },
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7yAgh-viglB"
      },
      "source": [
        "Now we've got predicted classes, let's evaluate them against the ground truth labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9OZbQu1-LPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48435da3-f435-4cb6-d265-462ccbc6f068"
      },
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.77165354330708,\n",
              " 'precision': 0.7675450859410361,\n",
              " 'recall': 0.7677165354330708,\n",
              " 'f1': 0.7667932666650168}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLm6r4nQ-Wdr"
      },
      "source": [
        "### Model 4: Bidirectonal RNN model \n",
        "\n",
        "\n",
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
        "\n",
        "Intuitively, this can be thought of as if you were reading a sentence for the first time in the normal fashion (left to right) but for some reason it didn't make sense so you traverse back through the words and go back over them again (right to left).\n",
        "\n",
        "\n",
        "However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAU9dvGm47_2"
      },
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "\n",
        "# Build a Bidirectional RNN in TensorFlow\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) \n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP1jeF0am9x0"
      },
      "source": [
        "# Compile\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtpYyjsbnEwN"
      },
      "source": [
        " we'll check out a summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sUd9AQ6nFXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f4889e-2216-441c-f4ac-59f917200840"
      },
      "source": [
        "# Get a summary of our bidirectional model\n",
        "model_4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvItfzeZnIE-"
      },
      "source": [
        "Notice the increased number of trainable parameters in `model_4` (bidirectional LSTM) compared to `model_2` (regular LSTM). This is due to the bidirectionality we added to our RNN.\n",
        "\n",
        "Time to fit our bidirectional model and track its performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAKY_QbHXPHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eeef9f3-bbe9-4dfb-8dc5-b90d011a8dcd"
      },
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20220905-173709\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 14s 43ms/step - loss: 0.5093 - accuracy: 0.7481 - val_loss: 0.4606 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.3135 - accuracy: 0.8708 - val_loss: 0.5144 - val_accuracy: 0.7690\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.2150 - accuracy: 0.9178 - val_loss: 0.5626 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.1523 - accuracy: 0.9469 - val_loss: 0.6365 - val_accuracy: 0.7769\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.1083 - accuracy: 0.9639 - val_loss: 0.6509 - val_accuracy: 0.7664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkt8GVRHoJz6"
      },
      "source": [
        "Due to the bidirectionality of our model we see a slight increase in training time.\n",
        "\n",
        "\n",
        "Let's make some predictions with it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFc7QHRtXmn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c910fc5e-e464-4b22-9c4b-80423dcfff29"
      },
      "source": [
        "# Make predictions with bidirectional RNN on the validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04000095],\n",
              "       [0.82792675],\n",
              "       [0.99842227],\n",
              "       [0.13531172],\n",
              "       [0.00311336],\n",
              "       [0.9922074 ],\n",
              "       [0.9552848 ],\n",
              "       [0.9994564 ],\n",
              "       [0.99898285],\n",
              "       [0.28141806]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_9HmNIYobDB"
      },
      "source": [
        "And we'll convert them to prediction classes and evaluate them against the ground truth labels and baseline model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5z8bMdaXw51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d00ebe2-ec63-4b1e-fd8b-fb194b1a3772"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a7Ym_vKYAO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88e42b0d-fd42-4a0c-b4c5-05e97730a777"
      },
      "source": [
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.64041994750657,\n",
              " 'precision': 0.7665895370389821,\n",
              " 'recall': 0.7664041994750657,\n",
              " 'f1': 0.7651213533864446}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcvt_7emuKlR"
      },
      "source": [
        "## Convolutional Neural Networks for Text\n",
        "\n",
        "You might've used convolutional neural networks (CNNs) for images before but they can also be used for sequences.\n",
        "\n",
        "The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n",
        "\n",
        "\n",
        "A typical CNN architecture for sequences will look like the following: \n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layers -> Outputs (class probabilities)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgXEorf9GWY1"
      },
      "source": [
        "### Model 5: Conv1D\n",
        "\n",
        " let's see a 1-dimensional convolutional layer (also called a **temporal convolution**) in action.\n",
        "\n",
        "We'll first create an embedding of a sample of text and experiment passing it through a `Conv1D()` layer and `GlobalMaxPool1D()` layer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the embedding, 1D convolutional and max pooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve over target sequence 5 words at a time\n",
        "conv_1d_output = conv_1d(embedding_test) # pass embedding through 1D convolutional layer\n",
        "max_pool = layers.GlobalMaxPool1D() \n",
        "max_pool_output = max_pool(conv_1d_output) # get the most important features\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "metadata": {
        "id": "Z4EnmuFhM2Dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb1bd38-3f9a-4317-c334-aa715edaed5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9aphPWCYkWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d383018-435a-46e7-f570-eae21440499c"
      },
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_5\")\n",
        "\n",
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of our 1D convolution model\n",
        "model_5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fzlaKm1ZrMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c828f95b-0216-45b8-bdc1-0e522de75685"
      },
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"Conv1D\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20220905-173837\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 25ms/step - loss: 0.5652 - accuracy: 0.7141 - val_loss: 0.4733 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 25ms/step - loss: 0.3380 - accuracy: 0.8615 - val_loss: 0.4758 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 6s 30ms/step - loss: 0.2070 - accuracy: 0.9234 - val_loss: 0.5457 - val_accuracy: 0.7730\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 26ms/step - loss: 0.1314 - accuracy: 0.9578 - val_loss: 0.6163 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0933 - accuracy: 0.9691 - val_loss: 0.6779 - val_accuracy: 0.7782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2up-1tLiXKD"
      },
      "source": [
        " Let's make some predictions with it and evaluate them just as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHYw5GkxZ2OK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f8c187-2d1f-4fdd-b1e9-2ef42d4a4dd5"
      },
      "source": [
        "# Make predictions with model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.22534508],\n",
              "       [0.75341123],\n",
              "       [0.99956024],\n",
              "       [0.05562782],\n",
              "       [0.01449853],\n",
              "       [0.98585176],\n",
              "       [0.9841893 ],\n",
              "       [0.99758804],\n",
              "       [0.9986262 ],\n",
              "       [0.26914358]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9YqTtjiaauS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef20ada9-5a3b-4747-c535-06101936a0bb"
      },
      "source": [
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMY3s1Pnaj34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749d2586-f598-47f4-a883-8c7d67e3fa0e"
      },
      "source": [
        "# Calculate model_5 evaluation metrics \n",
        "model_5_results = calculate_results(y_true=val_labels, \n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.82152230971128,\n",
              " 'precision': 0.7807522349051432,\n",
              " 'recall': 0.7782152230971129,\n",
              " 'f1': 0.7758810170952618}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_roVSSRt-7h"
      },
      "source": [
        "## Using Pretrained Embeddings (transfer learning for NLP)\n",
        "\n",
        "However, a common practice is to leverage pretrained embeddings through **transfer learning**. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned  and adjust it for our own use case.\n",
        "\n",
        "For our next model, instead of using our own embedding layer, we're going to replace it with a pretrained embedding layer.\n",
        "\n",
        "More specifically, we're going to be using the [Universal Sentence Encoder](https://www.aclweb.org/anthology/D18-2029.pdf) from [TensorFlow Hub](https://tfhub.dev/google/universal-sentence-encoder/4) (a great resource containing a plethora of pretrained model resources for a variety of tasks).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-NQ2MA5GZBo"
      },
      "source": [
        "### Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "\n",
        "Our embedding layer also outputs an a 128 dimensional vector for each word, where as, the Universal Sentence Encoder outputs a 512 dimensional vector for each sentence.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxYFDkGD-XjF"
      },
      "source": [
        "Passing our sentences to the Universal Sentence Encoder (USE) encodes them from strings to 512 dimensional vectors,\n",
        "\n",
        " let's build one with the USE as our embedding layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcbBj0aXqrs9"
      },
      "source": [
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "import tensorflow_hub as hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_pjIvPuYltA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6667a74d-8418-472e-ab07-ab6364616415"
      },
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yukgxOgCCR2Z"
      },
      "source": [
        "\n",
        "\n",
        "The trainable parameters are only in our output layers, in other words, we're keeping the USE weights frozen and using it as a feature-extractor.\n",
        "\n",
        "Now we've got a feature extractor model ready, let's train it and track its results to TensorBoard using our `create_tensorboard_callback()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX9S0YvafybG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5075218-3df1-406f-e4b0-0e23a28f22b7"
      },
      "source": [
        "# Train a classifier on top of pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20220905-174038\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 16ms/step - loss: 0.5008 - accuracy: 0.7892 - val_loss: 0.4478 - val_accuracy: 0.7966\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.4144 - accuracy: 0.8133 - val_loss: 0.4369 - val_accuracy: 0.8058\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.3998 - accuracy: 0.8212 - val_loss: 0.4329 - val_accuracy: 0.8110\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.3925 - accuracy: 0.8266 - val_loss: 0.4288 - val_accuracy: 0.8110\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3860 - accuracy: 0.8276 - val_loss: 0.4309 - val_accuracy: 0.8123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeI0kvVVDmbl"
      },
      "source": [
        "USE model trained! Let's make some predictions with it an evaluate them as we've done with our other models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeyNXqU-gM2p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7cc087d-5354-4ea7-d77c-9726b5ee3985"
      },
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.14443198],\n",
              "       [0.72715044],\n",
              "       [0.98566544],\n",
              "       [0.19740921],\n",
              "       [0.7341702 ],\n",
              "       [0.68596625],\n",
              "       [0.98088884],\n",
              "       [0.9741102 ],\n",
              "       [0.91573215],\n",
              "       [0.08070084]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbn1Z0FfgVdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7450be25-3e51-41e6-c583-4cd16ad7fc06"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Ow2de3okcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e07e4d-72c0-46f6-890a-51cfe36eb806"
      },
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.23359580052494,\n",
              " 'precision': 0.8148798668657973,\n",
              " 'recall': 0.8123359580052494,\n",
              " 'f1': 0.810686575717776}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBs9V61EGh0J"
      },
      "source": [
        "## Comparing the performance of each of our models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex0NSaz7lRf-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "d9a159e1-b660-48c7-d133-8eb316cd3b3d"
      },
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\n",
        "                                  \"simple_dense\": model_1_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"bidirectional\": model_4_results,\n",
        "                                  \"conv1d\": model_5_results,\n",
        "                                  \"tf_hub_sentence_encoder\": model_6_results\n",
        "                                 })\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          accuracy  precision    recall        f1\n",
              "simple_dense             78.740157   0.791492  0.787402  0.784697\n",
              "lstm                     75.065617   0.751008  0.750656  0.748927\n",
              "gru                      76.771654   0.767545  0.767717  0.766793\n",
              "bidirectional            76.640420   0.766590  0.766404  0.765121\n",
              "conv1d                   77.821522   0.780752  0.778215  0.775881\n",
              "tf_hub_sentence_encoder  81.233596   0.814880  0.812336  0.810687"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f3b198d-d08b-48be-9bef-9a671d8d3b8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>78.740157</td>\n",
              "      <td>0.791492</td>\n",
              "      <td>0.787402</td>\n",
              "      <td>0.784697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>75.065617</td>\n",
              "      <td>0.751008</td>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.748927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>76.771654</td>\n",
              "      <td>0.767545</td>\n",
              "      <td>0.767717</td>\n",
              "      <td>0.766793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>76.640420</td>\n",
              "      <td>0.766590</td>\n",
              "      <td>0.766404</td>\n",
              "      <td>0.765121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>77.821522</td>\n",
              "      <td>0.780752</td>\n",
              "      <td>0.778215</td>\n",
              "      <td>0.775881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tf_hub_sentence_encoder</th>\n",
              "      <td>81.233596</td>\n",
              "      <td>0.814880</td>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.810687</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f3b198d-d08b-48be-9bef-9a671d8d3b8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f3b198d-d08b-48be-9bef-9a671d8d3b8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f3b198d-d08b-48be-9bef-9a671d8d3b8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-s2DSLpmM1F"
      },
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp69bR8umD5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "2c5aa55e-9c44-478c-8be2-c2823d8a8491"
      },
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avbdkiIuKNNr"
      },
      "source": [
        "Looks like our pretrained USE TensorFlow Hub models have the best performance, even the one with only 10% of the training data seems to outperform the other models. This goes to show the power of transfer learning.\n",
        "\n",
        "How about we drill down and get the F1-score's of each model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yktdOiufmm3p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "6050a7f6-9432-4b4a-e12b-a322a649590b"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv2iE0TPGdNy"
      },
      "source": [
        "Drilling down into a single metric we see our USE TensorFlow Hub models performing  better than all of the other models. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpwErZOgX_nC"
      },
      "source": [
        "## Saving and loading a trained model\n",
        "\n",
        "\n",
        "\n",
        "Saving your models also enables you to export them for use elsewhere outside of your notebooks, such as in a web application.\n",
        "\n",
        "There are two main ways of [saving a model in TensorFlow](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model):\n",
        "1. The `HDF5` format. \n",
        "2. The `SavedModel` format (default).\n",
        "\n",
        "Let's take a look at both."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlwjGFVyX-_T"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSINZ0Q-nRb2"
      },
      "source": [
        "# Load model with custom Hub Layer (required with HDF5 format)\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\", \n",
        "                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4BCJ8iXnZ4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53af7df-411d-4a91-f1f3-194d4dd16891"
      },
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.4309 - accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43088313937187195, 0.8123359680175781]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02rbT4fwn0It"
      },
      "source": [
        "Calling the `save()` method on our target model and passing it a filepath allows us to save our model in the `SavedModel` format. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3eVaNBDoMsv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8800d005-ac0c-40e0-8d58-9bc220dd1989"
      },
      "source": [
        "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
        "model_6.save(\"model_6_SavedModel_format\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw3zf4fVoU5H"
      },
      "source": [
        "# Load TF Hub Sentence Encoder SavedModel\n",
        "loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqiPr6iiofi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6ece1e-a8d1-4622-e24c-4841d1e2879f"
      },
      "source": [
        "# Evaluate loaded SavedModel format\n",
        "loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 11ms/step - loss: 0.4309 - accuracy: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.43088313937187195, 0.8123359680175781]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0W3DWgWJCWs"
      },
      "source": [
        "## Making predictions on the test dataset\n",
        "\n",
        "Alright we've seen how our model's perform on the validation set.\n",
        "\n",
        "But how about the test dataset?\n",
        "\n",
        "We don't have labels for the test dataset so we're going to have to make some predictions and inspect them for ourselves.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q9lgqoDyequ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea120ec-7270-4c50-d446-10493de658c5"
      },
      "source": [
        "# Making predictions on the test dataset\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{test_sample}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0, Prob: 0.3970046639442444\n",
            "Text:\n",
            "RT SIGN URGENT Stop the Annihilation of the Salt River Wild Horses!!! #savewildhorses #saltriverhorses https://t.co/8AZjFF8eSi\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.13123738765716553\n",
            "Text:\n",
            "White Space Devices Pose Threat to Medical Devices Warns Lawmakers  http://t.co/kZ240R8qp9\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.36955633759498596\n",
            "Text:\n",
            "ThorCon: A Thorium Molten Salt Reactor System that can be built Now https://t.co/K90M1qoE9q #thorium #Auspol #climate #nuclearrcSA #nuclear\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.052306268364191055\n",
            "Text:\n",
            "Businesses are deluged with invoices. Make yours stand out with colour or shape and it's  ikely to rise to the to. of the pay' pile.\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.0721379742026329\n",
            "Text:\n",
            "Can You Afford Structural Failure? http://t.co/X3mKNITh7K\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.01603579707443714\n",
            "Text:\n",
            "@_Gags_ My Mommy will be devastated lol #NoMorePod\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.12115849554538727\n",
            "Text:\n",
            "I liked a @YouTube video http://t.co/2umSxRzot3 Zombie Apocalypse: The Rescue\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.15804141759872437\n",
            "Text:\n",
            "12' 72W CREE LED Work Light Bar Alloy Spot Flood Combo Diving Offroad 4WD Boat - Full readÛ_ http://t.co/8Mk9TD4RRL http://t.co/W20rH3Ai9J\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.39861565828323364\n",
            "Text:\n",
            "I swear theres a bud drought\n",
            "\n",
            "----\n",
            "\n",
            "Pred: 0, Prob: 0.01372057106345892\n",
            "Text:\n",
            "I would love to #win Suze's amazing filled #beauty #bag #giveaway! Contents from L'Occitane Body Shop &amp; Lavera. http://t.co/hEjJVVRsTY\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT1jhk8xdod5"
      },
      "source": [
        "## Predicting on Tweets from the wild\n",
        "\n",
        "How about we find some Tweets and use our model to predict whether or not they're about a diaster or not?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPbZaGznvbEx"
      },
      "source": [
        "Now we'll write a small function to take a model and an example sentence and return a prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyH9tn9upjld"
      },
      "source": [
        "def predict_on_sentence(model, sentence):\n",
        "  \"\"\"\n",
        "  Uses model to make a prediction on sentence.\n",
        "\n",
        "  Returns the sentence, the predicted label and the prediction probability.\n",
        "  \"\"\"\n",
        "  pred_prob = model.predict([sentence])\n",
        "  pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
        "  print(f\"Pred: {pred_label}\", \"(real disaster)\" if pred_label > 0 else \"(not real disaster)\", f\"Prob: {pred_prob[0][0]}\")\n",
        "  print(f\"Text:\\n{sentence}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvCG4RuUvj6d"
      },
      "source": [
        "Time to test our model out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYOfNacw08Of"
      },
      "source": [
        "\n",
        "\n",
        "How about we find a few Tweets about actual diasters?\n",
        "\n",
        "Such as the following two Tweets about the 2020 Beirut explosions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqILBsTK2i9R"
      },
      "source": [
        "# Source - https://twitter.com/BeirutCityGuide/status/1290696551376007168\n",
        "beirut_tweet_1 = \"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"\n",
        "\n",
        "# Source - https://twitter.com/BeirutCityGuide/status/1290773498743476224\n",
        "beirut_tweet_2 = \"#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvlbHDISrVmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7917cddc-afbd-4c29-d6f9-ff4ff87c371f"
      },
      "source": [
        "# Predict on diaster Tweet 1\n",
        "predict_on_sentence(model=model_6, \n",
        "                    sentence=beirut_tweet_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.9625465869903564\n",
            "Text:\n",
            "Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uKYx11p2zCd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce4ed56c-e0c7-45bf-f546-1b1787cc34c5"
      },
      "source": [
        "# Predict on diaster Tweet 2\n",
        "predict_on_sentence(model=model_6, \n",
        "                    sentence=beirut_tweet_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1.0 (real disaster) Prob: 0.9678557515144348\n",
            "Text:\n",
            "#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fczP1dFcwe98"
      },
      "source": [
        "Looks like our model is performing as expected, predicting both of the diaster Tweets as actual diasters.\n",
        "\n"
      ]
    }
  ]
}